{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ca27faf-c119-495c-9ce0-873a476c9173",
   "metadata": {},
   "source": [
    "https://ai.google.dev/edge/mediapipe/solutions/vision/image_embedder/python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8e2de-24a6-4ea2-af42-f11cd6ef0f7d",
   "metadata": {},
   "source": [
    "The MediaPipe Image Embedder task lets you convert image data into a numeric representation to accomplish ML-related image processing tasks, such as comparing the similarity of two images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3761c130-79e4-4d66-8719-d67dd4f6db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mediapipe\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python # Cross-platform APIs and libraries for deploying solutions.\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d659e1f-2436-42dd-976d-a7fb4482c4ee",
   "metadata": {},
   "source": [
    "The MediaPipe Image Embedder task requires a trained model that is compatible with this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9cbb8d9-50af-4125-8e3d-20e470d78226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mobilenet_v3_small_075_224_embedder.tflite'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "model_path = 'mobilenet_v3_small_075_224_embedder.tflite'\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c20a7a-7635-460a-86f7-65f0d652e0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mediapipe.python._framework_bindings.image.Image at 0x1271f6210>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "mp_image = mp.Image.create_from_file('IMG_0403.JPG')\n",
    "mp_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc313901-2a53-424c-8b49-22b0f00bb817",
   "metadata": {},
   "source": [
    "You can call the embed function corresponding to your running mode to trigger inferences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d5ff8d0-f87e-48a8-9ce4-e66d5a5bc323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751146354.384887 1175842 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "ImageEmbedder = mp.tasks.vision.ImageEmbedder\n",
    "ImageEmbedderOptions = mp.tasks.vision.ImageEmbedderOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "options = ImageEmbedderOptions(\n",
    "    base_options=BaseOptions(model_asset_path=  'mobilenet_v3_small_075_224_embedder.tflite' ),\n",
    "    quantize=True,\n",
    "    running_mode=VisionRunningMode.IMAGE)\n",
    "\n",
    "with ImageEmbedder.create_from_options(options) as embedder:\n",
    "  # The embedder is initialized.\n",
    "    # Perform image embedding on the provided single image.\n",
    "    embedding_result = embedder.embed(mp_image)\n",
    "\n",
    "    embedding_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5600628-4942-48eb-9a48-f15a3441e534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingResult(embeddings=[Embedding(embedding=array([209, 105, 127, ..., 219,  38,   0], dtype=uint8), head_index=0, head_name='feature')], timestamp_ms=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29f51fb-c41a-4635-b4c6-0458350ce688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
